{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adcacf60-5da6-494c-8cbc-430517724590",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/04/30 13:38:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Healthcare Export\") \\\n",
    "    .config(\"spark.driver.memory\", \"8g\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .config(\"spark.sql.catalog.local\", \"org.apache.iceberg.spark.SparkCatalog\") \\\n",
    "    .config(\"spark.sql.catalog.local.type\", \"hadoop\") \\\n",
    "    .config(\"spark.sql.catalog.local.warehouse\", \"/Users/neelkalavadiya/Practicum_Project_Local/iceberg_warehouse\") \\\n",
    "    .config(\"spark.sql.extensions\", \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Suppress all WARNs logs\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19095130-f387-4eff-a982-50dc0ade33d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, when, lit, current_timestamp\n",
    "\n",
    "# Load the cleaned parquet (output from Notebook 1)\n",
    "df_cleaned = spark.read.parquet(\"/Users/neelkalavadiya/Practicum_Project_Local/iceberg_warehouse/checkpoint_parquet/cleaning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f56690e-2dc1-4101-a53a-00a517aa7425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Enrichment --- #\n",
    "\n",
    "# Add ingestion timestamp\n",
    "df_enriched = df_cleaned.withColumn(\"silver_ingestion_ts\", current_timestamp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7fa7848-bac1-496f-ac42-1dc0f242060b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify payer category\n",
    "from pyspark.sql.functions import when\n",
    "\n",
    "payer_category_expr = when(col(\"payer_name\").rlike(\"(?i)aetna|cigna|humana|anthem|imagine health|blue cross\"), \"Commercial\") \\\n",
    "    .when(col(\"payer_name\").rlike(\"(?i)medicare|provider partners|devoted\"), \"Medicare\") \\\n",
    "    .when(col(\"payer_name\").rlike(\"(?i)medicaid|community first|molina\"), \"Medicaid\") \\\n",
    "    .when(col(\"plan_name\").rlike(\"(?i)HIX|exchange|blue advantage\"), \"Exchange\") \\\n",
    "    .otherwise(\"Other\")\n",
    "\n",
    "df_enriched = df_enriched.withColumn(\"payer_category\", payer_category_expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1b2573b-5421-4d8f-aabb-9f5f542841f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classify Pricing Model\n",
    "df_enriched = df_enriched.withColumn(\n",
    "    \"pricing_model\",\n",
    "    when(col(\"methodology\").rlike(\"(?i)case rate\"), \"Case Rate\")\n",
    "    .when(col(\"methodology\").rlike(\"(?i)fee schedule\"), \"Fee Schedule\")\n",
    "    .when(col(\"methodology\").rlike(\"(?i)percent|percentage\"), \"Percentage-Based\")\n",
    "    .otherwise(\"Other\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53fcec05-d00c-4eda-b4f2-7f2779b3c79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Plan Type\n",
    "df_enriched = df_enriched.withColumn(\n",
    "    \"plan_type\",\n",
    "    when(col(\"plan_name\").rlike(\"(?i)hmo\"), \"HMO\")\n",
    "    .when(col(\"plan_name\").rlike(\"(?i)ppo\"), \"PPO\")\n",
    "    .when(col(\"plan_name\").rlike(\"(?i)hix|exchange\"), \"Exchange\")\n",
    "    .when(col(\"plan_name\").rlike(\"(?i)medicare|medicaid\"), \"Government\")\n",
    "    .otherwise(\"Other\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0433c4eb-0cfd-420d-b331-c81d54a14063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bucket Standard Charges\n",
    "df_enriched = df_enriched.withColumn(\n",
    "    \"charge_bucket\",\n",
    "    when(col(\"standard_charge_dollar\") < 100, \"Low\")\n",
    "    .when(col(\"standard_charge_dollar\").between(100, 1000), \"Medium\")\n",
    "    .when(col(\"standard_charge_dollar\") > 1000, \"High\")\n",
    "    .otherwise(\"Unknown\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c8307ea-d041-4901-bce7-99b7a3b15794",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add Missing Payer Info Flag\n",
    "df_enriched = df_enriched.withColumn(\n",
    "    \"payer_info_missing\",\n",
    "    when(\n",
    "        col(\"payer_name\").isNull() |\n",
    "        col(\"plan_name\").isNull() |\n",
    "        col(\"methodology\").isNull(),\n",
    "        True\n",
    "    ).otherwise(False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3751a9f6-e459-4945-97f8-fcefdf20fb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify treatment types from service description (simplified rules)\n",
    "from pyspark.sql.functions import col, when, regexp_extract, lower\n",
    "\n",
    "# Treatment type based on keyword match\n",
    "df_enriched = df_enriched.withColumn(\n",
    "    \"treatment_type\",\n",
    "    when(lower(col(\"service_description\")).rlike(\"mri|ct|x-ray|ultrasound|imaging\"), \"Imaging\")\n",
    "    .when(lower(col(\"service_description\")).rlike(\"injection|inj|tablet|tb|cp|oral|syrup|mg|solution|suspension\"), \"Medication\")\n",
    "    .when(lower(col(\"service_description\")).rlike(\"biopsy|surgery|resection|repair|ablation|implant|arthroplasty|graft\"), \"Procedure\")\n",
    "    .when(lower(col(\"service_description\")).rlike(\"panel|ab/|antibody|lab|urine|test|analysis|level|quant\"), \"Lab Test\")\n",
    "    .when(lower(col(\"service_description\")).rlike(\"device|supply|graft|stent|pump|dressing\"), \"Supply/Device\")\n",
    "    .otherwise(\"Other\")\n",
    ")\n",
    "\n",
    "# is_medication flag\n",
    "df_enriched = df_enriched.withColumn(\n",
    "    \"is_medication\",\n",
    "    when(lower(col(\"service_description\")).rlike(\"mg|tb|cp|solution|suspension|syrup|inhalation|injection\"), True).otherwise(False)\n",
    ")\n",
    "\n",
    "# Drug form (simple classification)\n",
    "df_enriched = df_enriched.withColumn(\n",
    "    \"drug_form\",\n",
    "    when(lower(col(\"service_description\")).rlike(\"tb|tablet|cp\"), \"Tablet\")\n",
    "    .when(lower(col(\"service_description\")).rlike(\"inj|injection|ij\"), \"Injection\")\n",
    "    .when(lower(col(\"service_description\")).rlike(\"sol|solution\"), \"Solution\")\n",
    "    .when(lower(col(\"service_description\")).rlike(\"cream|ointment\"), \"Topical\")\n",
    "    .when(lower(col(\"service_description\")).rlike(\"inhalation|ih|is\"), \"Inhaler\")\n",
    "    .otherwise(\"Other\")\n",
    ")\n",
    "\n",
    "# Imaging Type (subset of treatment_type)\n",
    "df_enriched = df_enriched.withColumn(\n",
    "    \"imaging_type\",\n",
    "    when(lower(col(\"service_description\")).rlike(\"mri\"), \"MRI\")\n",
    "    .when(lower(col(\"service_description\")).rlike(\"ct\"), \"CT Scan\")\n",
    "    .when(lower(col(\"service_description\")).rlike(\"x-ray\"), \"X-Ray\")\n",
    "    .when(lower(col(\"service_description\")).rlike(\"ultrasound\"), \"Ultrasound\")\n",
    "    .otherwise(None)\n",
    ")\n",
    "\n",
    "# Lab test flag\n",
    "df_enriched = df_enriched.withColumn(\n",
    "    \"is_lab_test\",\n",
    "    when(lower(col(\"service_description\")).rlike(\"panel|antibody|test|level|urine|blood|cbc|cmp|lipid\"), True).otherwise(False)\n",
    ")\n",
    "\n",
    "# Brand indicator (recognizing known brand/device names)\n",
    "df_enriched = df_enriched.withColumn(\n",
    "    \"has_brand_indicator\",\n",
    "    when(lower(col(\"service_description\")).rlike(\"stryker|depuy|bard|zimmer|philips|medtronic|covidien|smith\"), True).otherwise(False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4995f115-ee1d-471e-ae0e-af080c1122de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Collect rows where rule-based logic failed\n",
    "other_descriptions = df_enriched.filter(col(\"treatment_type\") == \"Other\") \\\n",
    "    .select(\"service_description\") \\\n",
    "    .rdd.flatMap(lambda x: x).collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79a5001b-e3ed-434c-83fe-f71f9ee7dd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import rank, countDistinct, col, max as spark_max, expr\n",
    "\n",
    "# Rank prices within each service\n",
    "w_price = Window.partitionBy(\"service_description\").orderBy(\"standard_charge_dollar\")\n",
    "df_ranked = df_enriched.withColumn(\"price_rank\", rank().over(w_price))\n",
    "\n",
    "# Count payers per service\n",
    "coverage = df_enriched.groupBy(\"service_description\").agg(\n",
    "    countDistinct(\"payer_name\").alias(\"payer_coverage_count\")\n",
    ")\n",
    "df_with_coverage = df_ranked.join(coverage, on=\"service_description\", how=\"left\")\n",
    "\n",
    "# Define per-service max windows\n",
    "w_service = Window.partitionBy(\"service_description\")\n",
    "\n",
    "# Add max values per service for normalization\n",
    "df_norm = df_with_coverage \\\n",
    "    .withColumn(\"max_price_rank\", spark_max(\"price_rank\").over(w_service)) \\\n",
    "    .withColumn(\"max_coverage\", spark_max(\"payer_coverage_count\").over(w_service)) \\\n",
    "    .withColumn(\"score_price\", (col(\"max_price_rank\") - col(\"price_rank\")) / col(\"max_price_rank\")) \\\n",
    "    .withColumn(\"score_coverage\", col(\"payer_coverage_count\") / col(\"max_coverage\")) \\\n",
    "    .withColumn(\"score_brand\", col(\"has_brand_indicator\").cast(\"double\")) \\\n",
    "    .withColumn(\"final_score\", expr(\"score_price * 0.5 + score_coverage * 0.3 + score_brand * 0.2\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd926722-e600-457e-89a5-e2935f6a6e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import split, trim, regexp_extract, col\n",
    "\n",
    "# Split by comma\n",
    "df_address_split = df_norm.withColumn(\"street\", trim(split(\"hospital_address\", \",\")[0])) \\\n",
    "    .withColumn(\"city\", trim(split(\"hospital_address\", \",\")[1])) \\\n",
    "    .withColumn(\"state_zip\", trim(split(\"hospital_address\", \",\")[2]))\n",
    "\n",
    "# Further extract state and ZIP from state_zip\n",
    "df_address_cleaned = df_address_split \\\n",
    "    .withColumn(\"state\", regexp_extract(\"state_zip\", r\"([A-Z]{2})\", 1)) \\\n",
    "    .withColumn(\"zip_code\", regexp_extract(\"state_zip\", r\"(\\d{5})\", 1)) \\\n",
    "    .drop(\"state_zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "63853125-0b50-4e27-8407-29fcc5b6bedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping the following unnecessary columns:\n",
      " - street\n",
      " - score_brand\n",
      " - score_price\n",
      " - payer_coverage_count\n",
      " - zip_code\n",
      " - price_rank\n",
      " - hospital_location\n",
      " - score_coverage\n",
      " - additional_payer_notes\n",
      " - hospital_address\n",
      " - service_description\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Define columns to retain\n",
    "columns_to_keep = [\n",
    "    \"provider_id\", \"hospital_name\", \"city\", \"state\", \"last_updated_on\", \"license_number\", \n",
    "    \"license_state\", \"code\", \"modifiers\", \"code_type\", \"care_setting\",\n",
    "    \"gross_charge\", \"discounted_cash\", \"min_charge\", \"max_charge\",\n",
    "    \"payer_name\", \"plan_name\", \"billing_class\", \"methodology\",\n",
    "    \"standard_charge_dollar\", \"standard_charge_percentage\",\n",
    "    \"silver_ingestion_ts\", \"payer_category\", \"pricing_model\", \"plan_type\",\n",
    "    \"charge_bucket\", \"payer_info_missing\", \"treatment_type\", \"is_medication\",\n",
    "    \"drug_form\", \"imaging_type\", \"is_lab_test\", \"has_brand_indicator\", \"final_score\"\n",
    "]\n",
    "\n",
    "# Step 3: Determine columns to drop\n",
    "all_columns = df_address_cleaned.columns\n",
    "columns_to_drop = list(set(all_columns) - set(columns_to_keep))\n",
    "\n",
    "print(\"Dropping the following unnecessary columns:\")\n",
    "for col_name in columns_to_drop:\n",
    "    print(f\" - {col_name}\")\n",
    "\n",
    "# Step 4: Drop and create final DataFrame\n",
    "df_cleaned = df_address_cleaned.select([col(c) for c in columns_to_keep])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d3ac11b1-d4b5-42f0-9f45-7e8d1f94eb74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"DROP TABLE IF EXISTS local.silver.baptist_medical_center\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e512b227-b859-4723-8f56-b702cba697f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 5: Write to Iceberg silver table\n",
    "df_cleaned.writeTo(\"local.silver.baptist_medical_center\") \\\n",
    "    .using(\"iceberg\") \\\n",
    "    .tableProperty(\"format-version\", \"2\") \\\n",
    "    .createOrReplace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c28fd524-63be-496e-9d97-06dd22be7418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------------------------+-----------+\n",
      "|namespace|tableName                   |isTemporary|\n",
      "+---------+----------------------------+-----------+\n",
      "|silver   |baptist_medical_center_sa_tx|false      |\n",
      "|silver   |baptist_medical_center      |false      |\n",
      "+---------+----------------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW TABLES IN local.silver\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6a9a5dd7-37cb-4bfc-8a80-3991282d4ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|final_score       |\n",
      "+------------------+\n",
      "|0.7979674796747968|\n",
      "|0.7979674796747968|\n",
      "|0.7979674796747968|\n",
      "|0.7979674796747968|\n",
      "|0.7979674796747968|\n",
      "|0.7979674796747968|\n",
      "|0.7979674796747968|\n",
      "|0.7979674796747968|\n",
      "|0.7979674796747968|\n",
      "|0.7979674796747968|\n",
      "|0.7979674796747968|\n",
      "|0.7979674796747968|\n",
      "|0.7979674796747968|\n",
      "|0.7979674796747968|\n",
      "|0.7979674796747968|\n",
      "|0.7979674796747968|\n",
      "|0.7979674796747968|\n",
      "|0.7979674796747968|\n",
      "|0.7979674796747968|\n",
      "|0.7979674796747968|\n",
      "+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"Select final_score From local.silver.baptist_medical_center LIMIT 100\").show(truncate=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9abd4ba-4663-4331-aad4-077af8fd70ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
