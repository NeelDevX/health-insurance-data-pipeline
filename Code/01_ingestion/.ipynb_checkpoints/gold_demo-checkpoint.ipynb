{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adcacf60-5da6-494c-8cbc-430517724590",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/16 10:29:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/04/16 10:29:58 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/04/16 10:29:58 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "25/04/16 10:29:58 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Healthcare Export\") \\\n",
    "    .config(\"spark.driver.memory\", \"8g\") \\\n",
    "    .config(\"spark.jars\", \"/Users/neelkalavadiya/spark-jars/iceberg-spark-runtime-3.4_2.12-1.3.1.jar,\"\n",
    "                           \"/Users/neelkalavadiya/spark-jars/postgresql-42.7.2.jar\") \\\n",
    "    .config(\"spark.sql.catalog.local\", \"org.apache.iceberg.spark.SparkCatalog\") \\\n",
    "    .config(\"spark.sql.catalog.local.type\", \"hadoop\") \\\n",
    "    .config(\"spark.sql.catalog.local.warehouse\", \"/Users/neelkalavadiya/iceberg_warehouse\") \\\n",
    "    .config(\"spark.sql.extensions\", \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed65900c-5d04-4989-a42e-b842a6cdf951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------------------+-----------+\n",
      "|namespace|tableName                |isTemporary|\n",
      "+---------+-------------------------+-----------+\n",
      "|silver   |mission_trail_baptist    |false      |\n",
      "|silver   |hospital_demo            |false      |\n",
      "|silver   |santa_rosa_new_braunfels |false      |\n",
      "|silver   |resolute_health          |false      |\n",
      "|silver   |santa_rosa_westover_hills|false      |\n",
      "|silver   |north_central_baptist    |false      |\n",
      "|silver   |santa_rosa_medical_center|false      |\n",
      "|silver   |baptist_medical_center   |false      |\n",
      "+---------+-------------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW TABLES IN local.silver\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c28fd524-63be-496e-9d97-06dd22be7418",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from datetime import datetime\n",
    "\n",
    "# Read from Silver Layer\n",
    "silver_df = spark.read.table(\"local.silver.hospital_demo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0301b7a-d049-4b55-b3d6-c6fee15ccbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create gold timestamp\n",
    "current_ts = datetime.now()\n",
    "silver_df = silver_df.withColumn(\"gold_ingestion_ts\", F.lit(current_ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91049e10-a5e2-421b-8b6e-8503f8449d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Dim_Hospital\n",
    "hospital_dim = silver_df.select(\n",
    "    \"provider_id\", \"hospital_name\", \"city\", \"state\",\n",
    "    \"license_number\", \"license_state\"\n",
    ").dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "707ccc22-0dd0-4962-90c7-c4e319780fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Dim_Payer\n",
    "payer_dim = silver_df.select(\n",
    "    \"payer_name\", \"plan_name\", \"billing_class\", \"methodology\",\n",
    "    \"payer_category\", \"pricing_model\", \"plan_type\"\n",
    ").dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc707935-3ca8-44d9-8851-1e687019a7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Dim_Procedure\n",
    "procedure_dim = silver_df.select(\n",
    "    \"code\", \"modifiers\", \"code_type\", \"care_setting\",\n",
    "    \"treatment_type\", \"is_medication\", \"drug_form\",\n",
    "    \"imaging_type\", \"is_lab_test\", \"has_brand_indicator\"\n",
    ").dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6c0af73-04e3-461e-a23c-5d5009dd30e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fact Table: Fact_Charges\n",
    "fact_charges = silver_df.select(\n",
    "    \"provider_id\", \"payer_name\", \"code\",\n",
    "    \"gross_charge\", \"discounted_cash\", \"min_charge\", \"max_charge\",\n",
    "    \"standard_charge_dollar\", \"standard_charge_percentage\",\n",
    "    \"charge_bucket\", \"payer_info_missing\",\n",
    "    \"silver_ingestion_ts\", \"gold_ingestion_ts\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "192abc66-38d2-4940-afa3-d2b3b7608a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Save dimensions and fact tables as Parquet for inspection\n",
    "hospital_dim.write.mode(\"overwrite\").parquet(\"/Users/neelkalavadiya/iceberg_warehouse/checkpoint_parquet/transform/aggregation\")\n",
    "payer_dim.write.mode(\"overwrite\").parquet(\"/Users/neelkalavadiya/iceberg_warehouse/checkpoint_parquet/transform/aggregation\")\n",
    "procedure_dim.write.mode(\"overwrite\").parquet(\"/Users/neelkalavadiya/iceberg_warehouse/checkpoint_parquet/transform/aggregation\")\n",
    "fact_charges.write.mode(\"overwrite\").parquet(\"/Users/neelkalavadiya/iceberg_warehouse/checkpoint_parquet/transform/aggregation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "846c4ce4-03fb-453a-b980-8e51b6e75228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spark.sql(\"DROP TABLE IF EXISTS local.gold.dim_hospital_demo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec0c7ee8-52af-46a3-88af-c02710bbe673",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/16 10:34:01 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created and loaded table: local.gold.dim_hospital_demo\n",
      "Created and loaded table: local.gold.dim_payer_demo\n",
      "Created and loaded table: local.gold.dim_procedure_demo\n",
      "Created and loaded table: local.gold.fact_charges_demo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.utils import AnalysisException\n",
    "\n",
    "gold_tables = [\n",
    "    (hospital_dim, \"local.gold.dim_hospital_demo\"),\n",
    "    (payer_dim, \"local.gold.dim_payer_demo\"),\n",
    "    (procedure_dim, \"local.gold.dim_procedure_demo\"),\n",
    "    (fact_charges, \"local.gold.fact_charges_demo\")\n",
    "]\n",
    "\n",
    "for df, table in gold_tables:\n",
    "    try:\n",
    "        # Try to append to the existing table\n",
    "        df.writeTo(table) \\\n",
    "            .using(\"iceberg\") \\\n",
    "            .tableProperty(\"format-version\", \"2\") \\\n",
    "            .append()\n",
    "        print(f\"Appended to existing table: {table}\")\n",
    "    except AnalysisException:\n",
    "        # If table doesn't exist, create it\n",
    "        df.writeTo(table) \\\n",
    "            .using(\"iceberg\") \\\n",
    "            .tableProperty(\"format-version\", \"2\") \\\n",
    "            .create()\n",
    "        print(f\"Created and loaded table: {table}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "13332058-b819-4365-8c23-c8a1aec5b917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+-----------+\n",
      "|namespace|tableName    |isTemporary|\n",
      "+---------+-------------+-----------+\n",
      "|gold     |dim_hospital |false      |\n",
      "|gold     |dim_payer    |false      |\n",
      "|gold     |dim_procedure|false      |\n",
      "|gold     |fact_charges |false      |\n",
      "+---------+-------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW TABLES IN local.gold\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4f9a5b-b3a5-48a2-a04f-1989cefcba46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dim_check=spark.read.table(\"local.gold.dim_hospital_demo\")\n",
    "df_dim_check.show(10,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87f1af67-e426-45fa-9dab-c5d13b45ee55",
   "metadata": {},
   "outputs": [],
   "source": [
    "jdbc_url = \"jdbc:postgresql://localhost:5432/healthcare_insurance\"\n",
    "jdbc_properties = {\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"201970\",\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}\n",
    "\n",
    "df_dim_check.write \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", jdbc_url) \\\n",
    "    .option(\"dbtable\", \"dim_hospital_demo\") \\\n",
    "    .options(**jdbc_properties) \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cc167f-c051-46c7-ba1d-706990417187",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
