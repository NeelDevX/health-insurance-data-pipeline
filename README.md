# Health Insurance Data Engineering Pipeline 

An end-to-end data engineering pipeline for processing, transforming, and analyzing healthcare insurance data. Built using Apache Spark, Apache Iceberg, PostgreSQL, Apache Airflow, and Apache Superset â€” fully containerized with Docker Compose.


# ğŸ¥ Healthcare Data Engineering Project

This project builds a modular data engineering workflow using Docker Compose, integrating:

- ğŸ§ª **Apache Spark + Iceberg + Jupyter Lab** â€“ for data transformation
- ğŸ“Š **Apache Superset** â€“ for BI dashboards and visual analytics
- â° **Apache Airflow** â€“ for scheduling weekly ETL jobs
- ğŸ˜ **PostgreSQL** â€“ for storing gold-layer data
- ğŸ§  **Redis** â€“ for Airflow's broker backend

---

## ğŸ“ Folder Structure

```bash
.
â”œâ”€â”€ Dockerfile                    # Custom Spark + Iceberg + Jupyter image
â”œâ”€â”€ docker-compose.yml           # Multi-container setup
â”œâ”€â”€ notebooks/                   # Your Jupyter notebooks (Bronze â†’ Gold)
â”œâ”€â”€ iceberg_warehouse/           # Iceberg table warehouse
â”œâ”€â”€ airflow/
â”‚   â”œâ”€â”€ dags/                    # Airflow DAGs (ETL scheduling)
â”‚   â”œâ”€â”€ logs/
â”‚   â””â”€â”€ plugins/
â””â”€â”€ README.md
```

## In Terminal

```bash
git clone https://github.com/<your-org-or-username>/practicum_project.git
cd practicum_project

docker compose up --build
```
